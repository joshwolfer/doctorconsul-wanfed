global:
  enabled: false
  name: consul-cernunnos                          # Must be unique (not collide) with any other clusters in the same Consul DC. Because K8s auth. Oof 
  domain: consul
  datacenter: dc3
  image: hashicorp/consul-enterprise:1.17.1-ent                             # Select an image from: https://hub.docker.com/r/hashicorp/consul-enterprise/tags
  # imageEnvoy: "envoyproxy/envoy:v1.25.1"                                  # Pulls the latest supported when unspecified.
  # imageK8S: hashicorp/consul-k8s-control-plane:1.2.0-rc1                  # If an RC version of Consul is used, this needs to also be the matching RC version. And the Helm chart version will need to be the dev version. 9th circle of version matching Hell. 
  # imageConsulDataplane: "hashicorp/consul-dataplane:1.1.0"                # Pulls the latest when unspecified.

  # gossipEncryption:
  #   secretName: consul-gossip-encryption-key
  #   secretKey: key

  # ^^^ I shouldn't need a gossip key when it's a dataplane cluster.

  acls:
    manageSystemACLs: true
    bootstrapToken:
      secretName: consul-partitions-acl-token     # Partition token exported from DC3 and imported via k3d-config.sh
      secretKey: token

  tls:
    enabled: true                                 # Required for Peering
    httpsOnly: false                              # Turns on the HTTP UI
    enableAutoEncrypt: true
    caCert:                                     # Root CA Cert and Key exported from DC3 and imported via k3d-config.sh
      secretName: consul-ca-cert
      secretKey: tls.crt
    caKey:
      secretName: consul-ca-key
      secretKey: tls.key

  enableConsulNamespaces: true                        # CRDs won't setup Consul namespaces correctly if this is false (default)

  peering:
    enabled: true

  adminPartitions:
    enabled: true
    name: "cernunnos"

  enterpriseLicense:
    secretName: consul-license
    secretKey: key
    enableLicenseAutoload: true

externalServers:
  enabled: true
  # hosts: ["{{ .Values.DC3_LB_IP }}"]
  httpsPort: 443       # DC3 HTTPS API port (consul-ui loadbalancer)
  grpcPort: 8502       # DC3 exposed gRPC port (consul-expose-servers loadbalancer)
  # k8sAuthMethodHost: "{{ .Values.DC3_LB_IP }}"
  tlsServerName: "server.dc3.consul"
  skipServerWatch: true

meshGateway:
  enabled: True
  replicas: 1
  wanAddress:
    source: "Service"
    port: 8443
  service:
    type: LoadBalancer
    port: 8443

ui:
  enabled: false      # The UI can only be enabled on Servers. This is a Consul Dataplane + Partition cluster.


# prometheus:
#   enabled: true       

                      # How are we going to get UI prometheus stats from services in this kube cluster when the prometheus server is in DC3 cluster? 
                      # Who knows. 

apiGateway:
  enabled: false

connectInject:
  enabled: true
  default: false                 # Default
  transparentProxy:
    defaultEnabled: true         # Default
  cni:
    enabled: true
  consulNamespaces:
    consulDestinationNamespace: "default"   # Ignored when mirroringK8S is true
    mirroringK8S: true
    mirroringK8SPrefix: ""
  metrics:
    defaultEnabled: true
    defaultEnableMerging: false

syncCatalog:
  enabled: true
  k8sPrefix: null
  k8sDenyNamespaces: ["kube-system", "kube-public", "unicorn"]
  consulNamespaces:
    mirroringK8S: true
    mirroringK8SPrefix: ""
  # addK8SNamespaceSuffix: false        # Leave this disabled. It's a TRAP!!! if the service name matches the pod name, it'll get stomped.

# apiGateway:
#   enabled: true
#   imageEnvoy: envoyproxy/envoy:v1.23.1 # changed from 'latest'
#   image: hashicorppreview/consul-api-gateway:0.5-dev-b2f0fd134ce4a95f9097942cbfb73dc11c260f82
#   managedGatewayClass:
#     enabled: true
#     serviceType: LoadBalancer
#     copyAnnotations:
#       service:
#         annotations: |
#           - service.beta.kubernetes.io/aws-load-balancer-name
#           - service.beta.kubernetes.io/aws-load-balancer-type
#           - service.beta.kubernetes.io/aws-load-balancer-nlb-target-type
#           - service.beta.kubernetes.io/aws-load-balancer-scheme